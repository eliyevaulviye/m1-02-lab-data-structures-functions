{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ebc7ce",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d115ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 250 logs.\n",
      "Sample Entry: {'ticket_id': 'TKT-5000', 'category': 'Security', 'statuses': ['Resolved', 'In Progress', 'Closed', 'Escalated', 'Pending Vendor'], 'resolution_minutes': 68, 'priority': 'High'}\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def generate_support_logs(n=200):\n",
    "    \n",
    "    categories = ['Technical', 'Billing', 'Account Access', 'Feature Request', 'API Integration', 'Security']\n",
    "    cat_weights = [85, 55, 45, 25, 20, 20] # Total = 100%\n",
    "\n",
    "    statuses = ['Resolved', 'In Progress', 'Closed', 'Escalated', 'Pending Vendor']\n",
    "    stat_weights = [80, 60, 45, 30, 35]\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(n):\n",
    "        category = random.choices(categories, weights=cat_weights, k =1)[0]\n",
    "        status = random.choices(statuses, weights=stat_weights, k = 1)[0]\n",
    "\n",
    "        #Simulating dirty data with 12% of an issue\n",
    "\n",
    "        if random.random()<0.12:\n",
    "            resolution = random.choice([None, 'ERR_TIMEOUT', -99, \" \"])\n",
    "        else:\n",
    "            resolution = random.randint(2, 288)    \n",
    "\n",
    "        dataset.append({\n",
    "            'ticket_id' : f'TKT-{5000+i}',\n",
    "            'category' : category,\n",
    "            'statuses':statuses, \n",
    "            'resolution_minutes':resolution,\n",
    "            \"priority\": random.choice(['Low', 'Medium', 'High', 'Urgent'])\n",
    "        })    \n",
    "\n",
    "    return dataset\n",
    "\n",
    "raw_logs = generate_support_logs(250)\n",
    "print(f\"Generated {len(raw_logs)} logs.\")\n",
    "print(\"Sample Entry:\", raw_logs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd840a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Health Report ---\n",
      "Records with missing fields: 0\n",
      "Records with invalid resolution times: 34\n"
     ]
    }
   ],
   "source": [
    "def validate_structure(data, required_keys):\n",
    "    \"\"\"Checks for missing fields in any record.\"\"\"\n",
    "    missing = [r['ticket_id'] for r in data if not all(k in r for k in required_keys)]\n",
    "    return {\n",
    "        \"is_valid\": len(missing) == 0,\n",
    "        \"count_missing\": len(missing),\n",
    "        \"flagged_ids\": missing\n",
    "    }\n",
    "\n",
    "def find_numeric_anomalies(data, field_name):\n",
    "    \"\"\"\n",
    "    Identifies records where a specific field is not a positive number.\n",
    "    Returns a list of the full records for inspection.\n",
    "    \"\"\"\n",
    "    anomalies = []\n",
    "    for record in data:\n",
    "        val = record.get(field_name)\n",
    "        # Check: Is it an integer? Is it positive?\n",
    "        if not isinstance(val, int) or val < 0:\n",
    "            anomalies.append(record)\n",
    "    return anomalies\n",
    "\n",
    "# Running Validation\n",
    "fields = [\"ticket_id\", \"category\", \"statuses\", \"resolution_minutes\", \"priority\"]\n",
    "structure_report = validate_structure(raw_logs, fields)\n",
    "resolution_anomalies = find_numeric_anomalies(raw_logs, \"resolution_minutes\")\n",
    "\n",
    "print(f\"--- Data Health Report ---\")\n",
    "print(f\"Records with missing fields: {structure_report['count_missing']}\")\n",
    "print(f\"Records with invalid resolution times: {len(resolution_anomalies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1d2f9",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73be785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned. Before: 250 | After: 250\n",
      "Sample Cleaned Entry: {'ticket_id': 'TKT-5000', 'category': 'Security', 'statuses': ['Resolved', 'In Progress', 'Closed', 'Escalated', 'Pending Vendor'], 'resolution_minutes': 68, 'priority': 'High', 'was_repaired': False}\n"
     ]
    }
   ],
   "source": [
    "def clean_and_normalize(data):\n",
    "    # 1. Identify valid resolution times to calculate a replacement value (median)\n",
    "    valid_times = sorted([r['resolution_minutes'] for r in data if isinstance(r['resolution_minutes'], int) and r['resolution_minutes'] > 0])\n",
    "    median_res = valid_times[len(valid_times)//2] if valid_times else 60\n",
    "    \n",
    "    cleaned_data = []\n",
    "    \n",
    "    for record in data:\n",
    "        \n",
    "        clean_rec = record.copy()\n",
    "       \n",
    "        \n",
    "        # Normalize Category strings (Trimming and standardizing case)\n",
    "        clean_rec['category'] = clean_rec['category'].strip().title()\n",
    "        \n",
    "        # Repair resolution_minutes\n",
    "        val = clean_rec.get('resolution_minutes')\n",
    "        if not isinstance(val, int) or val <= 0:\n",
    "            clean_rec['resolution_minutes'] = median_res\n",
    "            clean_rec['was_repaired'] = True \n",
    "        else:\n",
    "            clean_rec['was_repaired'] = False\n",
    "            \n",
    "        cleaned_data.append(clean_rec)\n",
    "        \n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_logs = clean_and_normalize(raw_logs)\n",
    "print(f\"Data Cleaned. Before: {len(raw_logs)} | After: {len(cleaned_logs)}\")\n",
    "print(\"Sample Cleaned Entry:\", cleaned_logs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abd87d",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f8d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Security': {'avg_res_min': 129.75, 'escalation_rate': 0.0, 'volume': 20}, 'Feature Request': {'avg_res_min': 118.85, 'escalation_rate': 0.0, 'volume': 20}, 'Billing': {'avg_res_min': 137.6, 'escalation_rate': 0.0, 'volume': 57}, 'Account Access': {'avg_res_min': 144.56, 'escalation_rate': 0.0, 'volume': 43}, 'Technical': {'avg_res_min': 146.46, 'escalation_rate': 0.0, 'volume': 92}, 'Api Integration': {'avg_res_min': 136.5, 'escalation_rate': 0.0, 'volume': 18}} {'High': 57, 'Low': 67, 'Medium': 63, 'Urgent': 63}\n"
     ]
    }
   ],
   "source": [
    "def get_category_metrics(data):\n",
    "    metrics = {}\n",
    "    for r in data:\n",
    "        cat = r['category']\n",
    "        if cat not in metrics:\n",
    "            metrics[cat] = {'total_time': 0, 'count': 0, 'escalations': 0}\n",
    "        \n",
    "        metrics[cat]['total_time'] += r['resolution_minutes']\n",
    "        metrics[cat]['count'] += 1\n",
    "        if r['statuses'] == 'Escalated':\n",
    "            metrics[cat]['escalations'] += 1\n",
    "    \n",
    "    summary = {}\n",
    "    for cat, vals in metrics.items():\n",
    "        summary[cat] = {\n",
    "            \"avg_res_min\": round(vals['total_time'] / vals['count'], 2),\n",
    "            \"escalation_rate\": round(vals['escalations'] / vals['count'], 4),\n",
    "            \"volume\": vals['count']\n",
    "        }\n",
    "    \n",
    "    \n",
    "    assert sum(s['volume'] for s in summary.values()) == len(data)\n",
    "    return summary\n",
    "\n",
    "def get_priority_distribution(data):\n",
    "    dist = {}\n",
    "    for r in data:\n",
    "        p = r['priority']\n",
    "        dist[p] = dist.get(p, 0) + 1\n",
    "    return dist\n",
    "\n",
    "cat_summary = get_category_metrics(cleaned_logs)\n",
    "priority_dist = get_priority_distribution(cleaned_logs)\n",
    "print(cat_summary, priority_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634288be",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c16087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL SUPPORT LOG REPORT ---\n",
      "{\n",
      "  \"summary_metadata\": {\n",
      "    \"total_processed\": 250,\n",
      "    \"overall_escalation_rate\": \"0.0%\"\n",
      "  },\n",
      "  \"by_category\": {\n",
      "    \"Security\": {\n",
      "      \"avg_res_min\": 129.75,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 20\n",
      "    },\n",
      "    \"Feature Request\": {\n",
      "      \"avg_res_min\": 118.85,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 20\n",
      "    },\n",
      "    \"Billing\": {\n",
      "      \"avg_res_min\": 137.6,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 57\n",
      "    },\n",
      "    \"Account Access\": {\n",
      "      \"avg_res_min\": 144.56,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 43\n",
      "    },\n",
      "    \"Technical\": {\n",
      "      \"avg_res_min\": 146.46,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 92\n",
      "    },\n",
      "    \"Api Integration\": {\n",
      "      \"avg_res_min\": 136.5,\n",
      "      \"escalation_rate\": 0.0,\n",
      "      \"volume\": 18\n",
      "    }\n",
      "  },\n",
      "  \"priority_breakdown\": {\n",
      "    \"High\": 57,\n",
      "    \"Low\": 67,\n",
      "    \"Medium\": 63,\n",
      "    \"Urgent\": 63\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_final_report(data, cat_stats, prio_stats):\n",
    "    total_tickets = len(data)\n",
    "    total_escalated = sum(1 for r in data if r['statuses'] == 'Escalated')\n",
    "    \n",
    "    report = {\n",
    "        \"summary_metadata\": {\n",
    "            \"total_processed\": total_tickets,\n",
    "            \"overall_escalation_rate\": f\"{round((total_escalated / total_tickets) * 100, 2)}%\"\n",
    "        },\n",
    "        \"by_category\": cat_stats,\n",
    "        \"priority_breakdown\": prio_stats\n",
    "    }\n",
    "    return report\n",
    "\n",
    "final_report = generate_final_report(cleaned_logs, cat_summary, priority_dist)\n",
    "\n",
    "# Displaying a compact version of the report\n",
    "import json\n",
    "print(\"\\n--- FINAL SUPPORT LOG REPORT ---\")\n",
    "print(json.dumps(final_report, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
